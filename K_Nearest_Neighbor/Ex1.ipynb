{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Depth: k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k最近鄰居算法（簡稱KNN）是一種非常簡單的技術。\n",
    "\n",
    "首先儲存訓練數據集，而當需要預測時，然後找到與訓練數據集中的新記錄最相似的k個記錄(k-most similar records)。<br>從這些鄰居(neighbors)中，進行了匯總預測(summarized prediction)。<br><br>\n",
    "\n",
    "記錄之間的相似性可以用許多不同的方法來衡量。通常，使用表格數據時，建議可以使用歐幾里得距離(Euclidean distance)。<br>\n",
    "\n",
    "(KNN可以用於分類或回歸問題。)\n",
    "\n",
    "Reference: https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Iris Flower Species Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "鳶尾花數據集涉及根據花的觀測量來預測花的種類。<br>\n",
    "\n",
    "這是一個多類分類問題。每個類別的觀察次數是平衡的。<br>有150個觀測值，其中包含4個輸入變量和1個輸出變量。變量名稱如下：\n",
    "\n",
    "萼片長度、萼片寬度、花瓣長度、花瓣寬度、類(class)\n",
    "\n",
    "註: 此問題的基準性能(baseline performance)約為33％。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.1</th>\n",
       "      <th>3.5</th>\n",
       "      <th>1.4</th>\n",
       "      <th>0.2</th>\n",
       "      <th>Iris-setosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5.1  3.5  1.4  0.2  Iris-setosa\n",
       "0  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "1  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "2  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "3  5.0  3.6  1.4  0.2  Iris-setosa\n",
       "4  5.4  3.9  1.7  0.4  Iris-setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('iris.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors\n",
    "\n",
    "k-Nearest Neighbors分為3部分：<br><br>\n",
    "\n",
    "步驟1：計算歐幾里得距離。<br>\n",
    "步驟2：取得最近的鄰居。<br>\n",
    "步驟3：做出預測。<br><br>\n",
    "\n",
    "這些步驟將實現k-最近鄰居算法並將其應用於分類和回歸預測建模問題。<br><br>\n",
    "\n",
    "### 步驟1：計算歐幾里得距離<br>\n",
    "第一步是計算數據集中兩行之間的距離。<br><br>\n",
    "\n",
    "數據行(Rows of data)主要由數字組成，計算數字向量之間的距離的方法是繪製一條直線。<br><br>\n",
    "\n",
    "我們可以使用歐幾里得距離度量來計算兩個向量之間的直線距離。<br>\n",
    "它被計算為兩個向量之間平方差之和的平方根。<br><br>\n",
    "\n",
    "Euclidean Distance = sqrt(sum i to N (x1_i – x2_i)^2)<br>\n",
    "其中x1是數據的第一行，x2是數據的第二行，i是當我們跨所有列 求和時對特定列的索引。<br><br>\n",
    "\n",
    "對於歐幾里得距離，值越小，兩條記錄越相似。值為0表示兩個記錄之間沒有差異。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以觀察該函數假定每行的最後一列是一個輸出值，該值將從距離計算中忽略。 <br>\n",
    "\n",
    "我們可以使用一個人為分類數據集來測試該距離函數。 <br>\n",
    "下面列出了完整的範例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2014/09/Scatter-Plot-of-the-Small-Contrived-Dataset-for-Testing-the-KNN-Algorithm2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.3290173915275787\n",
      "1.9494646655653247\n",
      "1.5591439385540549\n",
      "0.5356280721938492\n",
      "4.850940186986411\n",
      "2.592833759950511\n",
      "4.214227042632867\n",
      "6.522409988228337\n",
      "4.985585382449795\n"
     ]
    }
   ],
   "source": [
    "# Example of calculating Euclidean distance\n",
    "from math import sqrt\n",
    " \n",
    "# calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "\tdistance = 0.0\n",
    "\tfor i in range(len(row1)-1):\n",
    "\t\tdistance += (row1[i] - row2[i])**2\n",
    "\treturn sqrt(distance)\n",
    " \n",
    "# Test distance function\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "\t[1.465489372,2.362125076,0],\n",
    "\t[3.396561688,4.400293529,0],\n",
    "\t[1.38807019,1.850220317,0],\n",
    "\t[3.06407232,3.005305973,0],\n",
    "\t[7.627531214,2.759262235,1],\n",
    "\t[5.332441248,2.088626775,1],\n",
    "\t[6.922596716,1.77106367,1],\n",
    "\t[8.675418651,-0.242068655,1],\n",
    "\t[7.673756466,3.508563011,1]]\n",
    "row0 = dataset[0]\n",
    "for row in dataset:\n",
    "\tdistance = euclidean_distance(row0, row)\n",
    "\tprint(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步驟2：取得最近的鄰居\n",
    "新數據的鄰居是k個最接近的實例(k closest instances)，這由我們的距離度量定義。<br><br>\n",
    "\n",
    "為了在數據集中找到新數據的鄰居，我們必須首先計算數據集中每個記錄到新數據之間的距離。<br>\n",
    "我們可以使用上面準備的距離函數來做到這一點。<br><br>\n",
    "\n",
    "一旦計算出距離，我們就必鬚根據它們與新數據的距離對訓練數據集中的所有記錄進行排序。<br>\n",
    "然後，我們可以選擇頂部k作為最相似的鄰居返回。<br><br>\n",
    "\n",
    "我們可以通過以元組的形式跟踪數據集中每個記錄的距離，通過距離（按降序）對元組列表進行排序，<br>\n",
    "然後檢索鄰居來做到這一點。<br><br>\n",
    "\n",
    "下面是一個名為get_neighbors（）的函數，用於實現此功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the most similar neighbors\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您可以看到在上一步中開發的euclidean_distance（）函數用於計算每個train_row和新的test_row之間的距離。<br><br>\n",
    "\n",
    "在使用自定義鍵的地方對train_row和distance元組的列表進行排序，<br>\n",
    "以確保在排序操作中使用了元組中的第二項（tup[1]）。<br><br>\n",
    "\n",
    "最後，列表num_neighbors最相似的鄰居test_row返回。<br><br>\n",
    "\n",
    "我們可以使用上一部分中準備的人為數據集來測試此功能。<br>\n",
    "下面列出了完整的範例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7810836, 2.550537003, 0]\n",
      "[3.06407232, 3.005305973, 0]\n",
      "[1.465489372, 2.362125076, 0]\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    " \n",
    "# calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)\n",
    " \n",
    "# Locate the most similar neighbors\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors\n",
    " \n",
    "# Test distance function\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "    [1.465489372,2.362125076,0],\n",
    "    [3.396561688,4.400293529,0],\n",
    "    [1.38807019,1.850220317,0],\n",
    "    [3.06407232,3.005305973,0],\n",
    "    [7.627531214,2.759262235,1],\n",
    "    [5.332441248,2.088626775,1],\n",
    "    [6.922596716,1.77106367,1],\n",
    "    [8.675418651,-0.242068655,1],\n",
    "    [7.673756466,3.508563011,1]]\n",
    "neighbors = get_neighbors(dataset, dataset[0], 3)\n",
    "for neighbor in neighbors:\n",
    "    print(neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此範例將按相似性順序將數據集中的3個最相似的記錄打印到第一條記錄。<br>\n",
    "第一條記錄與其最相似，並且位於列表的頂部。<br>\n",
    "現在我們知道瞭如何從數據集中獲取鄰居，我們可以使用它們進行預測。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步驟3：做出預測\n",
    "從訓練數據集中收集的最相似的鄰居可以用來進行預測。<br><br>\n",
    "\n",
    "在分類的情況下，我們可以返回最代表的類(most represented class)。<br><br>\n",
    "\n",
    "我們可以通過對鄰居的輸出值列表執行max（）函數來實現此目的。<br>\n",
    "給定在鄰居中觀察到的類值列表，max（）函數採用一組唯一的類值，<br>\n",
    "並為該集中的每個類值調用類值列表中的計數。<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 0, Got 0.\n"
     ]
    }
   ],
   "source": [
    "# Example of making predictions\n",
    "from math import sqrt\n",
    " \n",
    "# calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)\n",
    " \n",
    "# Locate the most similar neighbors\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors\n",
    " \n",
    "# Make a classification prediction with neighbors\n",
    "def predict_classification(train, test_row, num_neighbors):\n",
    "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "    output_values = [row[-1] for row in neighbors]\n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    return prediction\n",
    " \n",
    "# Test distance function\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "    [1.465489372,2.362125076,0],\n",
    "    [3.396561688,4.400293529,0],\n",
    "    [1.38807019,1.850220317,0],\n",
    "    [3.06407232,3.005305973,0],\n",
    "    [7.627531214,2.759262235,1],\n",
    "    [5.332441248,2.088626775,1],\n",
    "    [6.922596716,1.77106367,1],\n",
    "    [8.675418651,-0.242068655,1],\n",
    "    [7.673756466,3.508563011,1]]\n",
    "prediction = predict_classification(dataset, dataset[0], 3)\n",
    "print('Expected %d, Got %d.' % (dataset[0][-1], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們可以想像如何可以更改predict_classification()函數以計算結果值的平均值。\n",
    "\n",
    "現在，我們擁有使用KNN進行預測的所有方法。讓我們將其應用於真實數據集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Flower Species Case Study\n",
    "\n",
    "我們將使用5-fold 交叉驗證(k-fold cross-validation)來評估算法。<br>\n",
    "即是指每個fold 中將有150/5 = 30個記錄。<br>\n",
    "我們將使用輔助函數validate_algorithm（）來評估具有交叉驗證的算法，<br>\n",
    "並使用precision_metric（）來計算預測的準確性。<br><br>\n",
    "\n",
    "開發了一個名為k_nearest_neighbors（）的新函數來管理KNN算法的應用，<br>\n",
    "首先從訓練數據集中學習統計信息，然後使用它們為測試數據集做出預測。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [96.66666666666667, 96.66666666666667, 100.0, 90.0, 100.0]\n",
      "Mean Accuracy: 96.667%\n"
     ]
    }
   ],
   "source": [
    "# k-nearest neighbors on the Iris Flowers Dataset\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        value_min = min(col_values)\n",
    "        value_max = max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax\n",
    "\n",
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    "\n",
    "# Calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)\n",
    "\n",
    "# Locate the most similar neighbors\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors\n",
    "\n",
    "# Make a prediction with neighbors\n",
    "def predict_classification(train, test_row, num_neighbors):\n",
    "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "    output_values = [row[-1] for row in neighbors]\n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    return prediction\n",
    "\n",
    "# kNN Algorithm\n",
    "def k_nearest_neighbors(train, test, num_neighbors):\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        output = predict_classification(train, row, num_neighbors)\n",
    "        predictions.append(output)\n",
    "    return(predictions)\n",
    "\n",
    "# Test the kNN on the Iris Flowers dataset\n",
    "seed(1)\n",
    "filename = 'iris.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])-1):\n",
    "    str_column_to_float(dataset, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "num_neighbors = 5\n",
    "scores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們可以看到，平均準確度約為96.6％，遠高於基線準確度33％。<br>\n",
    "可以使用訓練數據集為新的觀測值（數據行）做出預測。<br>\n",
    "\n",
    "這涉及到對predict_classification（）函數的調用，其中一行代表了我們用來預測類標籤的新觀察結果。<br>\n",
    "\n",
    "我們也可能想知道用於預測的類標籤（字符串）。<br><br>\n",
    "我們可以更新str_column_to_int（）函數以印出字串(string)類名稱映射到的整數，以便解釋模型所做的預測。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "        print('[%s] => %d' % (value, i))\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面列出了將KNN與整個數據集結合使用並對單個觀測值進行單個預測的完整範例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iris-setosa] => 0\n",
      "[Iris-versicolor] => 1\n",
      "[Iris-virginica] => 2\n",
      "Data=[5.7, 2.9, 4.2, 1.3], Predicted: 1\n"
     ]
    }
   ],
   "source": [
    "# Make Predictions with k-nearest neighbors on the Iris Flowers Dataset\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "        print('[%s] => %d' % (value, i))\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        value_min = min(col_values)\n",
    "        value_max = max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax\n",
    "\n",
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# Calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)\n",
    "\n",
    "# Locate the most similar neighbors\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors\n",
    "\n",
    "# Make a prediction with neighbors\n",
    "def predict_classification(train, test_row, num_neighbors):\n",
    "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "    output_values = [row[-1] for row in neighbors]\n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    return prediction\n",
    "\n",
    "# Make a prediction with KNN on Iris Dataset\n",
    "filename = 'iris.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])-1):\n",
    "    str_column_to_float(dataset, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "# define model parameter\n",
    "num_neighbors = 5\n",
    "# define a new record\n",
    "row = [5.7,2.9,4.2,1.3]\n",
    "# predict the label\n",
    "label = predict_classification(dataset, row, num_neighbors)\n",
    "print('Data=%s, Predicted: %s' % (row, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "運行數據首先總結了 類標籤到整數的映射，然後將模型擬合到整個數據集。<br>\n",
    "然後定義一個新的觀察值（在這種情況下，我從數據集中取了一行），併計算了預測的標籤。<br>\n",
    "\n",
    "在這種情況下，我們的觀測值預測為屬於1類，我們知道這是\"iris-setosa\"。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
