{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Explaining-Decision-Trees-and-Random-Forests\" data-toc-modified-id=\"Explaining-Decision-Trees-and-Random-Forests-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Explaining Decision Trees and Random Forests</a></div><div class=\"lev1 toc-item\"><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import Libraries</a></div><div class=\"lev1 toc-item\"><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load Data</a></div><div class=\"lev1 toc-item\"><a href=\"#Build-Model\" data-toc-modified-id=\"Build-Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Build Model</a></div><div class=\"lev2 toc-item\"><a href=\"#Create-Feature-Contribution\" data-toc-modified-id=\"Create-Feature-Contribution-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Create Feature Contribution</a></div><div class=\"lev1 toc-item\"><a href=\"#Visualizing-Decision-Trees\" data-toc-modified-id=\"Visualizing-Decision-Trees-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Visualizing Decision Trees</a></div><div class=\"lev2 toc-item\"><a href=\"#Regression\" data-toc-modified-id=\"Regression-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Regression</a></div><div class=\"lev2 toc-item\"><a href=\"#Binary-Classification\" data-toc-modified-id=\"Binary-Classification-52\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Binary Classification</a></div><div class=\"lev2 toc-item\"><a href=\"#Multinomial-Classification\" data-toc-modified-id=\"Multinomial-Classification-53\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Multinomial Classification</a></div><div class=\"lev1 toc-item\"><a href=\"#Plot-Feature-Importances\" data-toc-modified-id=\"Plot-Feature-Importances-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Plot Feature Importances</a></div><div class=\"lev1 toc-item\"><a href=\"#Plot-Feature-Contributions\" data-toc-modified-id=\"Plot-Feature-Contributions-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Plot Feature Contributions</a></div><div class=\"lev1 toc-item\"><a href=\"#Plotting-Individual-Features\" data-toc-modified-id=\"Plotting-Individual-Features-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Plotting Individual Features</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining Decision Trees and Random Forests\n",
    "\n",
    "This notebook shows examples of how the `treeinterpreter` (<a href='https://github.com/andosa/treeinterpreter'>https://github.com/andosa/treeinterpreter</a>) library works and provides some insightful plots to gain a deeper understanding of what a decision tree or random forest is doing.\n",
    "\n",
    "I have created a set of useful plotting functions in the file `tree_interp_functions.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:16.371337Z",
     "start_time": "2017-08-25T21:18:15.432308Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'treeinterpreter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0dc8a156dd63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                          \u001b[0mexport_graphviz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtreeinterpreter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtreeinterpreter\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mti\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'treeinterpreter'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor,\\\n",
    "                         export_graphviz\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "import pydotplus\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from tree_interp_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:16.405928Z",
     "start_time": "2017-08-25T21:18:16.373368Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set default matplotlib settings\n",
    "plt.rcParams['figure.figsize'] = (10, 7)\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "plt.rcParams['figure.titlesize'] = 26\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 16\n",
    "\n",
    "# Set seaborn colours\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('colorblind')\n",
    "blue, green, red, purple, yellow, cyan = sns.color_palette('colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "We will use the abalone data set as an example. We would like to show how this works for decision tree and random forest regressors as well as classifiers. We use the `rings` variable as our continuous variable and create a binary variable from it to indicate whether `rings > 9`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:16.457076Z",
     "start_time": "2017-08-25T21:18:16.407517Z"
    }
   },
   "outputs": [],
   "source": [
    "column_names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\", \n",
    "                \"shucked weight\", \"viscera weight\", \"shell weight\", \"rings\"]\n",
    "abalone_df = pd.read_csv('abalone.csv', names=column_names)\n",
    "abalone_df['sex'] = abalone_df['sex'].map({'F': 0, 'M': 1, 'I': 2})\n",
    "abalone_df['y'] = abalone_df.rings.map(lambda x: 1 if x > 9 else 0)\n",
    "abalone_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we do a simple train/test split of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:16.497926Z",
     "start_time": "2017-08-25T21:18:16.458593Z"
    }
   },
   "outputs": [],
   "source": [
    "abalone_train, abalone_test = train_test_split(abalone_df, test_size=0.2,\n",
    "                                               random_state=0)\n",
    "\n",
    "X_train = abalone_train.drop(['sex', 'rings', 'y'], axis=1)\n",
    "y_train_bin_clf = abalone_train.y\n",
    "y_train_multi_clf = abalone_train.sex\n",
    "y_train_reg = abalone_train.rings\n",
    "\n",
    "X_test = abalone_test.drop(['sex', 'rings', 'y'], axis=1)\n",
    "y_test_bin_clf = abalone_test.y\n",
    "y_test_multi_clf = abalone_test.sex\n",
    "y_test_reg = abalone_test.rings\n",
    "\n",
    "X_train = X_train.copy().reset_index(drop=True)\n",
    "y_train_bin_clf = y_train_bin_clf.copy().reset_index(drop=True)\n",
    "y_train_multi_clf = y_train_multi_clf.copy().reset_index(drop=True)\n",
    "y_train_reg = y_train_reg.copy().reset_index(drop=True)\n",
    "X_test = X_test.copy().reset_index(drop=True)\n",
    "y_test_bin_clf = y_test_bin_clf.copy().reset_index(drop=True)\n",
    "y_test_multi_clf = y_test_multi_clf.copy().reset_index(drop=True)\n",
    "y_test_reg = y_test_reg.copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:16.541841Z",
     "start_time": "2017-08-25T21:18:16.499673Z"
    }
   },
   "outputs": [],
   "source": [
    "abalone_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "Now, we build simple decision tree and random forest models. We will limit the depth of the decision tree to show how the interpretation works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:16.587920Z",
     "start_time": "2017-08-25T21:18:16.543363Z"
    }
   },
   "outputs": [],
   "source": [
    "dt_bin_clf = DecisionTreeClassifier(criterion='entropy', max_depth=3,\n",
    "                                    random_state=0)\n",
    "dt_bin_clf.fit(X_train, y_train_bin_clf)\n",
    "\n",
    "dt_multi_clf = DecisionTreeClassifier(criterion='entropy', max_depth=2,\n",
    "                                      random_state=0)\n",
    "dt_multi_clf.fit(X_train, y_train_multi_clf)\n",
    "\n",
    "dt_reg = DecisionTreeRegressor(criterion='mse', max_depth=3,\n",
    "                               random_state=0)\n",
    "dt_reg.fit(X_train, y_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:18.522316Z",
     "start_time": "2017-08-25T21:18:16.589672Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_bin_clf = RandomForestClassifier(criterion='entropy', max_depth=10,\n",
    "                                    n_estimators=100, random_state=0)\n",
    "rf_bin_clf.fit(X_train, y_train_bin_clf)\n",
    "\n",
    "rf_multi_clf = RandomForestClassifier(criterion='entropy', max_depth=10,\n",
    "                                      n_estimators=100, random_state=0)\n",
    "rf_multi_clf.fit(X_train, y_train_multi_clf)\n",
    "\n",
    "rf_reg = RandomForestRegressor(criterion='mse', max_depth=10,\n",
    "                               n_estimators=100, random_state=0)\n",
    "rf_reg.fit(X_train, y_train_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Feature Contribution\n",
    "We use the `ti.predict` function to get our predictions, biases, and contributions. The contributions matrix is a 3d array which represents the contribution for each example, feature, and class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:25.363206Z",
     "start_time": "2017-08-25T21:18:18.524251Z"
    }
   },
   "outputs": [],
   "source": [
    "dt_bin_clf_pred, dt_bin_clf_bias, dt_bin_clf_contrib = ti.predict(dt_bin_clf, X_test)\n",
    "rf_bin_clf_pred, rf_bin_clf_bias, rf_bin_clf_contrib = ti.predict(rf_bin_clf, X_test)\n",
    "\n",
    "dt_multi_clf_pred, dt_multi_clf_bias, dt_multi_clf_contrib = ti.predict(dt_multi_clf, X_test)\n",
    "rf_multi_clf_pred, rf_multi_clf_bias, rf_multi_clf_contrib = ti.predict(rf_multi_clf, X_test)\n",
    "\n",
    "dt_reg_pred, dt_reg_bias, dt_reg_contrib = ti.predict(dt_reg, X_test)\n",
    "rf_reg_pred, rf_reg_bias, rf_reg_contrib = ti.predict(rf_reg, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Decision Trees\n",
    "We can visualize a decision tree by using graphviz. This will show every path down to the leaves and the proportion of the two classes in each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:25.557339Z",
     "start_time": "2017-08-25T21:18:25.364819Z"
    }
   },
   "outputs": [],
   "source": [
    "reg_dot_data = export_graphviz(dt_reg,\n",
    "                               out_file=None,\n",
    "                               feature_names=X_train.columns\n",
    "                              )\n",
    "reg_graph = pydotplus.graph_from_dot_data(reg_dot_data)\n",
    "Image(reg_graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:25.745409Z",
     "start_time": "2017-08-25T21:18:25.558906Z"
    }
   },
   "outputs": [],
   "source": [
    "bin_clf_dot_data = export_graphviz(dt_bin_clf,\n",
    "                                   out_file=None,\n",
    "                                   feature_names=X_train.columns\n",
    "                                  )\n",
    "bin_clf_graph = pydotplus.graph_from_dot_data(bin_clf_dot_data)\n",
    "Image(bin_clf_graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:25.885292Z",
     "start_time": "2017-08-25T21:18:25.747665Z"
    }
   },
   "outputs": [],
   "source": [
    "multi_clf_dot_data = export_graphviz(dt_multi_clf,\n",
    "                                     out_file=None,\n",
    "                                     feature_names=X_train.columns\n",
    "                                    )\n",
    "multi_clf_graph = pydotplus.graph_from_dot_data(multi_clf_dot_data)\n",
    "Image(multi_clf_graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-26T11:38:13.781428Z",
     "start_time": "2017-05-26T11:38:13.778326Z"
    },
    "collapsed": true
   },
   "source": [
    "# Plot Feature Importances\n",
    "Feature importances, which are built into sklearn, are a more standard way to understand decision trees and random forests. They describe how well a given feature splits the population. However, they do not give any insight into the directionality of the feature, i.e., how exactly it affects the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:26.215840Z",
     "start_time": "2017-08-25T21:18:25.886919Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_importances = pd.DataFrame({'features': X_train.columns,\n",
    "                               'importances': dt_bin_clf.feature_importances_\n",
    "                              })\n",
    "df_importances\\\n",
    "    .set_index('features')\\\n",
    "    .sort_values('importances')\\\n",
    "    .plot(kind='barh')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Plot Feature Contributions\n",
    "We can use feature contributions to better understand decision trees and random forests. Unlike feature importances, feature contributions are not numbers representative of the entire data set, but for a single observation. More specifically, it depends on which leaf/leaves the observation falls into. We show feature contributions for two examples, where we order the features by their absolute contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:26.759989Z",
     "start_time": "2017-08-25T21:18:26.217419Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in xrange(2):\n",
    "    df, labels, pred = plot_obs_feature_contrib(rf_bin_clf,\n",
    "                                                rf_bin_clf_contrib,\n",
    "                                                X_test,\n",
    "                                                y_test_bin_clf,\n",
    "                                                i,\n",
    "                                                class_index=1,\n",
    "                                                num_features=5,\n",
    "                                                order_by='contribution'\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the function also returns a DataFrame of the contributions, labels, and predictions in a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:26.799438Z",
     "start_time": "2017-08-25T21:18:26.761400Z"
    }
   },
   "outputs": [],
   "source": [
    "display(df)\n",
    "print 'Label: {}'.format(labels)\n",
    "print 'Predicted probabilities: {}'.format(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also order them by their natural ordering, i.e., how they appear in the table. This will allow us to compare directly between observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:27.350515Z",
     "start_time": "2017-08-25T21:18:26.801263Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in xrange(2):\n",
    "    df, labels, pred = plot_obs_feature_contrib(rf_bin_clf,\n",
    "                                                rf_bin_clf_contrib,\n",
    "                                                X_test,\n",
    "                                                y_test_bin_clf,\n",
    "                                                i,\n",
    "                                                class_index=1,\n",
    "                                                order_by='natural'\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot them against the contributions of all observations by using violin plots. This will show the given observation's contributions against the entire population's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:27.952085Z",
     "start_time": "2017-08-25T21:18:27.352202Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(2):\n",
    "    df, labels, pred = plot_obs_feature_contrib(rf_bin_clf,\n",
    "                                                rf_bin_clf_contrib,\n",
    "                                                X_test,\n",
    "                                                y_test_bin_clf,\n",
    "                                                i,\n",
    "                                                class_index=1,\n",
    "                                                order_by='contribution',\n",
    "                                                violin=True\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:28.559102Z",
     "start_time": "2017-08-25T21:18:27.953636Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in xrange(2):\n",
    "    df, labels, pred = plot_obs_feature_contrib(rf_bin_clf,\n",
    "                                                rf_bin_clf_contrib,\n",
    "                                                X_test,\n",
    "                                                y_test_bin_clf,\n",
    "                                                i,\n",
    "                                                class_index=1,\n",
    "                                                order_by='natural',\n",
    "                                                violin=True\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Individual Features\n",
    "We now plot individual feature values against their contribution. This should give us some pattern on how each feature affects the contribution of that feature in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:29.189274Z",
     "start_time": "2017-08-25T21:18:28.560688Z"
    }
   },
   "outputs": [],
   "source": [
    "col_name = 'shucked weight'\n",
    "\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "fig.set_figheight(20)\n",
    "abalone_test[[col_name, 'rings']].plot(x=col_name, y='rings',\n",
    "                                       kind='scatter', ax=ax[0])\n",
    "plot_single_feat_contrib(col_name, dt_bin_clf_contrib, X_test, ax=ax[1])\n",
    "plot_single_feat_contrib(col_name, rf_bin_clf_contrib, X_test, ax=ax[2])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `plot_single_feat_contrib` function is also setup to not need the `ax` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:29.406291Z",
     "start_time": "2017-08-25T21:18:29.190719Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_single_feat_contrib(col_name, dt_bin_clf_contrib, X_test,\n",
    "                         class_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:29.624925Z",
     "start_time": "2017-08-25T21:18:29.407724Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_single_feat_contrib('shell weight', rf_bin_clf_contrib, X_test,\n",
    "                         class_index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add a <a href='http://www.statisticshowto.com/lowess-smoothing/'>LOWESS</a> smoothing curve to the data to see a trend curve by adding the tag `add_smooth=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:29.924815Z",
     "start_time": "2017-08-25T21:18:29.626415Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_single_feat_contrib('shell weight', rf_bin_clf_contrib, X_test,\n",
    "                         class_index=1, add_smooth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LOWESS curve takes in a `frac` parameter, which specifies the fraction of data in a neighbourhood around the point to use to do linear regression. We put the feature in as an option here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:30.223453Z",
     "start_time": "2017-08-25T21:18:29.926371Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_single_feat_contrib('shell weight', rf_bin_clf_contrib, X_test,\n",
    "                         class_index=1, add_smooth=True, frac=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:30.253700Z",
     "start_time": "2017-08-25T21:18:30.224951Z"
    }
   },
   "outputs": [],
   "source": [
    "colours = [blue, green, red]\n",
    "class_names = ['Sex = {}'.format(s) for s in ('F', 'M', 'I')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:30.942376Z",
     "start_time": "2017-08-25T21:18:30.255933Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, sharey=True)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "for i in xrange(3):\n",
    "    plot_single_feat_contrib('shell weight', dt_multi_clf_contrib, X_test,\n",
    "                             class_index=i, class_name=class_names[i],\n",
    "                             c=colours[i], ax=ax[i])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-25T21:18:31.843641Z",
     "start_time": "2017-08-25T21:18:30.943829Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, sharey=True)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "for i in xrange(3):\n",
    "    plot_single_feat_contrib('shell weight', rf_multi_clf_contrib, X_test,\n",
    "                             class_index=i, class_name=class_names[i],\n",
    "                             add_smooth=True, c=colours[i], ax=ax[i])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
